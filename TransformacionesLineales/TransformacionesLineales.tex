% ****************************************************************************************
% ******************        TRANSFORMACIONES LINEALES     ********************************
% ****************************************************************************************

% =======================================================
% =======         HEADER FOR DOCUMENT        ============
% =======================================================
    % *********   DOCUMENT ITSELF   **************
    \documentclass[12pt]{report}                                    %Type of docuemtn and size of font
    \usepackage[margin=1.2in]{geometry}                             %Margins and Geometry pacakge
    \usepackage{ifthen}                                             %Allow simple programming
    \usepackage{hyperref}                                           %Create MetaData for a PDF and LINKS!
    \setlength{\parindent}{0pt}                                     %Eliminate ugly indentation
    \author{Oscar Andrés Rosas}                                     %Who I am

    % *********   LANGUAJE AND UFT-8   *********
    \usepackage[spanish]{babel}                                     %Please use spanish
    \usepackage[utf8]{inputenc}                                     %Please use spanish - UFT
    \usepackage[T1]{fontenc}                                        %Please use spanish

    % *********   MATH AND HIS STYLE  *********
    \usepackage{amsthm, amssymb, amsfonts, mathrsfs}                %Make math beautiful
    \usepackage[fleqn]{amsmath}                                     %Please make equations left
    \decimalpoint                                                   %Use decimal point

    % *********   GRAPHICS AND IMAGES *********
    \usepackage{graphicx}                                           %Allow to create graphics
    \usepackage{wrapfig}                                            %Allow to create images
    \graphicspath{ {Graphics/} }                                    %Where are the images :D

    % *********   LISTS AND TABLES ***********
    \usepackage{listings}                                           %We will be using code here
    \usepackage[inline]{enumitem}                                   %We will need to enumarate
    \usepackage{tasks}                                              %Horizontal lists
    \usepackage{longtable}                                          %Lets make tables awesome


    % *********   HEADERS AND FOOTERS ********
    \usepackage{fancyhdr}                                           %Lets make awesome headers/footers
    \pagestyle{fancy}                                               %Lets make awesome headers/footers
    \setlength{\headheight}{16pt}                                   %Top line
    \setlength{\parskip}{0.5em}                                     %Top line
    \renewcommand{\footrulewidth}{0.5pt}                            %Bottom line

    \lhead{                                                         %Left Header
        \hyperlink{chapter.\arabic{chapter}}                        %Make a link to the current chapter
        {\normalsize{\textsc{\nouppercase{\leftmark}}}}             %And fot it put the name
    }

    \rhead{                                                         %Right Header
        \hyperlink{section.\arabic{chapter}.\arabic{section}}       %Make a link to the current chapter
            {\footnotesize{\textsc{\nouppercase{\rightmark}}}}      %And fot it put the name
    }

    \rfoot{\textsc{\small{\hyperref[sec:Index]{Ve al Índice}}}}    %This will always be a footer  

    \fancyfoot[L]{                                                  %Algoritm for a changing footer
        \ifthenelse{\isodd{\value{page}}}                           %IF ODD PAGE:
            {\href{https://compilandoconocimiento.com/yo/}          %DO THIS:
                {\footnotesize                                      %Send the page
                    {\textsc{Oscar Andrés Rosas}}}}                 %Send the page
            {\href{https://compilandoconocimiento.com}              %ELSE DO THIS: 
                {\footnotesize                                      %Send the author
                    {\textsc{Compilando Conocimiento}}}}            %Send the author
    }
    
    
    
% ========================================
% ===========   COMMANDS    ==============
% ========================================
    \DeclareMathOperator \Real {\mathbb{R}}
    \DeclareMathOperator \Complex {\mathbb{C}}
    \DeclareMathOperator \LinealTransformation {\mathcal{T}}



% =====================================================
% ============        COVER PAGE       ================
% =====================================================
\begin{document}
\begin{titlepage}

    \center
    % ============ UNIVERSITY NAME AND DATA =========
    \textbf{\textsc{\Large Proyecto Compilando Conocimiento}}\\[1.0cm] 
    \textsc{\Large Algebra Lineal}\\[1.0cm] 

    % ============ NAME OF THE DOCUMENT  ============
    \rule{\linewidth}{0.5mm} \\[1.0cm]
        { \huge \bfseries Transformaciones Lineales}\\[1.0cm] 
    \rule{\linewidth}{0.5mm} \\[2.0cm]
    
    % ====== SEMI TITLE ==========
    {\LARGE Transformaciones Lineales}\\[7cm] 
    
    % ============  MY INFORMATION  =================
    \begin{center} \large
    \textbf{\textsc{Autor:}}\\
    Rosas Hernandez Oscar Andres
    \end{center}

    \vfill

\end{titlepage}


% =====================================================
% ========                INDICE              =========
% =====================================================
\tableofcontents{}
\label{sec:Index}


\clearpage

% ======================================================================================
% =============================    TRANSFORMACIONES LINEALES    ========================
% ======================================================================================
\chapter{Transformaciones Lineales}
\label{sec:TransformacionesLineales}
    \clearpage

    % =====================================================
    % ============           DEFINICION            ========
    % =====================================================
    \section{Definición}
        Sea $V$ y $W$ dos espacios vectoriales sobre un \textbf{mismo} campo $K$. Una
        transformación lineal de $V \to W$ es una función que cumpla con esto:

        $\LinealTransformation: V \to W $ tal que $\forall v_1, v_2 \in V $ y $\forall \alpha \in K$
        tenemos que se cumple que:

        \begin{itemize}
            \item $\LinealTransformation (v_1 + v_2) = \LinealTransformation(v_1) + \LinealTransformation(v_2)$
            \item $\LinealTransformation (\alpha v_1) = \alpha \LinealTransformation(v_1)$ 
        \end{itemize}

        \subsubsection{Combinación Lineal}
        Podemos tambien tener que como consecuencia de lo que tenemos arriba que podemos
        encontrar que $\LinealTransformation$ es una transformación lineal si y solo si se cumple que:

        $\forall v_1, v_2 \in V$ y $\forall \alpha, \beta \in K$ se cumple que:
        \begin{equation}
            \LinealTransformation(\alpha v_1 + \beta v_2) = \alpha \LinealTransformation(v_1) + \beta \LinealTransformation(v_2)
        \end{equation}

        \subsubsection{Saber si algo es una $\LinealTransformation$}
        Así que para probar que una $\LinealTransformation$ es o no transformación lineal basta con verificar
        que se cumplan las 2 propiedades originales. 

        % ========================
        % =====   EJEMPLO   ======
        % ========================
        \clearpage
        \subsubsection{Ejemplos}
            Sea $\mathbb{R}^3 \to \mathbb{R}^2$ tal que:
            \begin{equation*}
                \LinealTransformation\left( \begin{matrix} x\\y\\z \end{matrix} \right) =
                \left( \begin{matrix} x-z\\y+z \end{matrix} \right)
            \end{equation*}

            Probemos la primera propiedad como:
            \begin{equation*}
            \begin{split}
                \LinealTransformation (v_1 + v_2) & =
                \LinealTransformation \left( \begin{matrix} x_1\\y_1\\z_1 \end{matrix} + \begin{matrix} x_2\\y_2\\z_2 \end{matrix} \right)
                \\
                & = \LinealTransformation \left( \begin{matrix} x_1+x_2\\y_1+y_2\\z_1+z_2 \end{matrix} \right)
                  = \begin{matrix} (x_1+x_2)-(z_1+z_2) \\ (y_1+y_2)+(z_1+z_2) \end{matrix}
                  = \begin{matrix}(x_1-z_1)\\(y_1+z_1)\end{matrix} + \begin{matrix}(x_2-z_2)\\(y_2+z_2)\end{matrix} 
                  = 
                  \LinealTransformation \left(\begin{matrix} x_1\\y_1\\z_1 \end{matrix} \right)
                  +
                  \LinealTransformation \left( \begin{matrix} x_2\\y_2\\z_2 \end{matrix} \right)            
                \\
                & = \LinealTransformation(v_1) + \LinealTransformation(v_2)
            \end{split}
            \end{equation*}

            Probemos la segunda propiedad:
            \begin{equation*}
            \begin{split}
                \LinealTransformation (\alpha v_1) & =
                \LinealTransformation \left( \alpha \cdot \begin{matrix} x\\y\\z \end{matrix} \right) \\
                & = \LinealTransformation \left( \begin{matrix} \alpha x\\ \alpha y\\ \alpha z\end{matrix} \right) =
                \begin{matrix} \alpha x - \alpha z\\ \alpha y + \alpha z\end{matrix}  =
                \alpha \cdot \begin{matrix}x-z\\y+z\end{matrix} =
                \alpha \LinealTransformation \left( \begin{matrix}x\\y\\z\end{matrix} \right) \\
                & = \alpha \LinealTransformation(v_1)
            \end{split}
            \end{equation*}

        Por lo tanto las 2 propiedades se cumplen así que si que es una transformación lineal.


    % =====================================================
    % ============       PROPIEDADES            ===========
    % =====================================================
    \clearpage
    \section{Propiedades}

        \subsubsection{El $0_v$ se preserva}
            Una Transformación Lineal debe llevar al $0_v$ de $V$ al $0_v$ de $W$

            Su demostración es muy sencilla, pues
            $\LinealTransformation(0_v)=\LinealTransformation(v_v-v_v)=\LinealTransformation(v_v)-\LinealTransformation(v_v)=0_w$

        \subsubsection{Operador Lineal}
            Decimos que $\LinealTransformation$ (alguna transformación lineal) es un
            operador lineal en V si y solo si su dominio y su contradominio son el mismo.


% ======================================================================================
% =============================       KERNEL E IMAGEN              =====================
% ======================================================================================
\chapter{Kernel e Imagen}

    % ==================================================
    % ===================   KERNEL    ==================
    % ==================================================
    \clearpage
    \section{Kernel}
        \subsubsection{Definición}
        \textbf{El Kernel} de una Transformación Lineal o \textbf{Núcleo} es el conjunto 
        de todos los vectores originales (osea $v \in V$) tales que al momento de
        aplicarles la transformación estos son llevados al origen (osea $0_w$)

        O dicho con el bello lenguaje de matemáticas:
        \begin{equation}
            Kernel(\LinealTransformation) = \{v \in V |\quad \LinealTransformation(v) = 0_w\}
        \end{equation}

        Recuerda que un Kernel siempre siempre sera un Subespacio Vectorial y solemos
        llamar a su dimensión la 'Nulidad'.

        Podemos decir que el Kernel es el espacio solución del Sistema Homogeneo.
        \begin{equation*}
            \{x \in K^m |\quad Ax = 0_{m \times 1} \}
        \end{equation*}

        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Encuentra el Kernel de la siguiente Transformación Lineal:
            $\LinealTransformation : \mathbb{R}^3 \to \mathbb{R}_2[x]$ tal que: 
            $\LinealTransformation(a,b,c) = (a+b) + (a-c)x + (2a+b-c)x^2$

            Lo que nos estan pidiendo es:
            \begin{equation*}
                Kernel(\LinealTransformation) = 
                \{(a,b,c)\in \mathbb{R}^3 |\quad \LinealTransformation(a,b,c) = 0+0x+0x^2\}
            \end{equation*}

            Veamos que para hacerlo solo basta con que cumplan que:
            \begin{equation*}
            \begin{split}
                a + b       & = 0 \\
                a - c       & = 0 \\
                2a + b + c  & = 0 \\
            \end{split}
            \end{equation*}

            Podemos hacer Gauss - Jordan:
            \begin{equation*}
                \begin{pmatrix} 1&1&0 \\ 1&0&-1 \\ 2&1&-1 \\\end{pmatrix} \to
                \begin{pmatrix} 1&1&0 \\ 1&0&-1 \\ 1&0&-1 \\\end{pmatrix} \to
                \begin{pmatrix} 1&1&0 \\ 1&0&-1 \\ 0&0&0  \\\end{pmatrix}
            \end{equation*}

            Por lo tanto podemos ver que:
            \begin{equation*}
            \begin{split}
                a + b = 0 &\to a = -b  \\
                a - c = 0 &\to a = c   \\
             \end{split}
            \end{equation*}

            Por lo tanto podemos ver que:
            \begin{equation*}
                Kernel(\LinealTransformation) = \{(a,b,c)\in R^3 |\quad a = -b, a=c\}
            \end{equation*}

            Finalmente aplicamos la transformación con estas propiedades y tenemos que:
            \begin{equation*}
                Kernel(\LinealTransformation) = \{(a,-a,a)\in \mathbb{R}^3 |\quad a \in \mathbb{R}\}
            \end{equation*}

            Y si te das cuenta estas ya describiendo un espacio vectorial que esta definido como:
            \begin{equation*}
                Kernel(\LinealTransformation) = \{\alpha(1,-1,1) |\quad \alpha\in \mathbb{R}\}
            \end{equation*}

            Sera tal vez una linea, pero no deja de ser espacio vectorial, cuyo vector base es:
            \begin{equation*}
                Kernel(\LinealTransformation) = <(1,-1,1)>
            \end{equation*}


    % ===================================================
    % ===================   IMAGEN    ===================
    % ===================================================
    \clearpage
    \section{Imágen}
        Tambien tenemos a la hermana perdida del Kernel, la llamamos la \textbf{Imágen},
        la cual la definimos así:

        \subsubsection{Definición}
        La imágen de una Transformación Lineal es el conjunto de todos los vectores
        nuevos (osea $w \in W$) que podemos 'crear' desde los vectores originales
        (osea $v \in V$) usando la Transformación Lineal.

        O dicho con el bello lenguaje de matemáticas:
        \begin{equation}
            Imagen(\LinealTransformation) = \{w \in W |\quad \exists v \in V ,\quad \LinealTransformation(v) = w\}
        \end{equation}

        Recuerda que una Imagen siempre siempre sera un Espacio Vectorial y solemos
        llamar a su dimensión 'Rango'.

        Podemos decir que el Imagen es el conjunto de terminos independientes para los cuales
        hay solución.
        \begin{equation*}
            \{b \in K^m |\quad \exists x \in K^m, Ax = b \}
        \end{equation*}


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Encuentra la Imagen de la siguiente Transformación Lineal:
            $\LinealTransformation : \mathbb{R}^3 \to \mathbb{R}_2[x]$ tal que: 
            $\LinealTransformation(a,b,c) = (a+b) + (a-c)x + (2a+b-c)x^2$

            Lo que nos estan pidiendo es:
            \begin{equation*}
                Imagen(\LinealTransformation) = 
                \{a_0+a_1x+a_2x^2 \in R_2[x] |\quad \exists (a,b,c) \in R^3 ,\quad 
                \LinealTransformation(a,b,c) = a_0+a_1x+a_2x^2\}
            \end{equation*}

            Es decir, lo que se nos esta pidiendo es que:
            \begin{equation*}
            \begin{split}
                a + b           & = a_0 \\
                a - c           & = a_1 \\
                2a + b + c      & = a_2 \\
             \end{split}
            \end{equation*}

            Y pos preguntas para que valores de $a_0, a_1, a_2$ tiene solución el 
            sistema que planteamos allá arriba.

            Es decir lo que tenemos que hacer es ver las soluciones de
            este sistema de ecuaciones, podemos hacer Gauss - Jordan:
            \begin{equation*}
                \begin{pmatrix} 1&1&0 \\ 1&0&-1 \\ 2&1&-1 \\\end{pmatrix} 
                \begin{pmatrix} a_0 \\ a_1 \\ a_2 \\\end{pmatrix}
                \to_{Usando: Gauss-Jordan}
                \begin{pmatrix} 1&1&0 \\ 1&0&-1 \\ 0&0&0 \\\end{pmatrix}
                \begin{pmatrix} a_1 & \\ a_0-a_1 &\\ a_2-a_1-a_0 &\\\end{pmatrix}
            \end{equation*}

            Por lo tanto podemos ver que:
            \begin{equation*}
                a_2-a_1-a_0 = 0
                \quad \to \quad
                a_2 = a_1 + a_0
            \end{equation*}

            Y ya solo sustituyendo tenemos que:
            \begin{equation*}
            \begin{split}
                Imagen(\LinealTransformation) 
                & = \{a_0+a_1x+(a_0+a_1)x^2 \in R_2[x] |\quad a_2 = a_0 + a_1, |\quad a_0, a_1 \in \mathbb{R}\}  \\
                & = \{a_0(1+x^2) +a_1(x+x^2) \in R_2[x] |\quad a_0, a_1 \in \mathbb{R}\}
            \end{split}
            \end{equation*}

            Y si te das cuenta estas ya describiendo un espacio vectorial que esta definido como:
            \begin{equation*}
                Imagen(\LinealTransformation) = \{\alpha(1+x^2) + \beta(x+x^2) |\quad \alpha, \beta \in \mathbb{R}\}
            \end{equation*}

            Y cuyos vectores base son:
            \begin{equation*}
                Imagen(\LinealTransformation) = <(1+x^2) , (x+x^2)>
            \end{equation*}

    % ===================================================
    % ============   PROPIEDADES    =====================
    % ===================================================
    \clearpage
    \section{Propiedades de Ambas}
        Podemos hablar de que ambas paracen ser como hermanas perdidas,
        veamos que propiedades tenemos:

        \begin{itemize}
            \item Llamemos Rango a $Dim(Imagen(\LinealTransformation))$
            \item Llamemos Nulidad a $Dim(Kernel(\LinealTransformation))$
            \item Ambas \textbf{Son SubEspacios Vectoriales}.
            \item Estas deacuerdo que todos los vectores o bien son llevados al cero
            vector o no, así que tiene sentido hablar de que  \textbf{La Suma de la Nulidad
            con el Rango te da la dimensión de V}, es decir: $dim(V) = dim(Kernel)+dim(Imagen)$
        \end{itemize}


% ======================================================================================
% ==========================       BIYECTIVA Y SUPRAYECTIVA        =====================
% ======================================================================================
\chapter{Tipos de Transformaciones}

    % =====================================================
    % ========      SUPRAYECTIVA E INYECTIVAS       =======
    % =====================================================
    \clearpage
    \section{Inyectiva y Supreyectiva}
        Vamos a declarar muchas cosas, así que empecemos:
        \begin{itemize}
            \item Sea $\LinealTransformation : V \to W $ una transformación lineal.
            \item Sea $S \subseteq V$ donde $S$ es un conjunto de vectores base (tal que $<S> = V$)
            \item Además sean $v_1, v_2, \cdots \in V$ y linealmente independientes.
        \end{itemize}
        
        Obviamente sabemos que $<\LinealTransformation(S)> = Imagen(\LinealTransformation)$

        \subsection{Suprayectiva}
        Recuerda que el hecho de que una función $f(x)$ sea suprayectiva si es que existe para cualquier
        $y$ podemos encontrar a una $x$ tal que $f(x)=y$.
        Esto tambien lo podemos ver si es que $Imagen(f)= y$

        $\LinealTransformation$ es suprayectiva si y solo si $<\LinealTransformation(s)> = W$

        Esto lo que nos dice es a que vectores puedo alcanzar basicamente. 


        \subsection{Inyectiva}
        Recuerda que el hecho de una función $f(x)$ sea inyectiva si es que para cualquiera $x_1, x_2$
        que pase que $f(x_1) = f(x_2)$ implica que $x_1=x_2$.


        $\LinealTransformation$ es inyectiva si y solo si $Kernel(\LinealTransformation) = \{0_v\}$

        Ademas podemos saber que si $\LinealTransformation$ es inyectiva, entonces 
        $\LinealTransformation(v_1)+\LinealTransformation(v_2)+\cdots$ son linealmente independientes.

        % ====================================
        % =========   PROPIEDADES    =========
        % ====================================
        \clearpage
        \subsection{Propiedades}

        Sea $\LinealTransformation_1 : V \to W $ y $\LinealTransformation_2 : W \to U $
        transformaciones lineales.

        \begin{itemize}
            \item Si $\LinealTransformation_1$ es biyectiva,entonces
            $\LinealTransformation_1^-1: W \to V$ también es una Transformación Lineal.

            \item $\LinealTransformation_2 \circ \LinealTransformation_1: V \to U$
            es una Transformación Lineal.
        \end{itemize}

        Podemos también saber esta interesante propiedad:\\
        Sea $\LinealTransformation: V \to W$ tal que: $dim(V) = n$ y la $dim(W)=m$
        \begin{itemize}
            \item Si $n > m$, $\LinealTransformation$ no es inyectiva.
            \item Si $n < m$, $\LinealTransformation$ no es suprayectiva.
        \end{itemize}


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Verificar si las siguiente transformación lineal si es biyectiva ó inyectiva:
            $\LinealTransformation : \mathbb{R}^2 \to \mathbb{R}_2[x]$ tal que: 
            $\LinealTransformation(\begin{matrix}a\\b\end{matrix}) = (a-b) + (a)x + (a+b)x^2$

            \textbf{\\Inyectiva}

            Para ver que lo es, lo que podemos ver es que el Kernel de la transformación lineal
            solo tendrá al $0_v$, veamos que podemos ver que esto se cumple porque:
            $\begin{matrix}a\\b\end{matrix} \in Kernel$

            Entonces sabemos que para lograr el cero vector a tiene que ser cero (porque es lo 
            único que multiplica a $x$) y ahora sabemos que b también pues $(a+b)x^2=0x^2$

            Por lo tanto si que el Kernel solo tiene al $0_v$ y por lo tanto esta transformada si que es Inyectiva.


            \textbf{\\Suprayectiva}

            Para que fuera supreyectiva, una base de $\mathbb{R}^2$ tras ser transformada debería ser un capaz de
            generar a $\mathbb{R}_2[x]$ pero propongamos a la base canonica de  $ \mathbb{R}^2$ y esta no puede
            ser base para $\mathbb{R}_2[x]$ pues necesito mínimo 3 vectores para generar a $\mathbb{R}_2[x]$.

            Por lo tanto no es Suprayectiva.


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Verificar si las siguiente transformación lineal si es biyectiva ó inyectiva:
            $\LinealTransformation : M_{2 \times 2}(\mathbb{R}) \to \mathbb{R}^3$ tal que: 
            $\LinealTransformation(\begin{matrix}a&b\\c&d\end{matrix}) = \begin{pmatrix}a-b+c\\d-c\\-a+b-c\end{pmatrix}$

            \textbf{\\Inyectiva}

            Podemos verlo usando la contrapositiva de una proposión mas famosa, basicamente es que si
            tienes un conjunto de de vectores base al momento de crear la transformación lineal estos son dependientes, 
            entonces no es inyectiva, y eso lo podemos ver con la base canonica:

            \begin{equation*}
                \LinealTransformation(\begin{matrix}1&0\\0&0\end{matrix}) = \begin{pmatrix}1\\0\\-1\end{pmatrix}, 
                \LinealTransformation(\begin{matrix}0&1\\0&0\end{matrix}) = \begin{pmatrix}-1\\0\\1\end{pmatrix}, 
                \LinealTransformation(\begin{matrix}0&0\\1&0\end{matrix}) = \begin{pmatrix}1\\-1\\-1\end{pmatrix}, 
                \LinealTransformation(\begin{matrix}0&0\\0&1\end{matrix}) = \begin{pmatrix}0\\1\\0\end{pmatrix} 
            \end{equation*}

            Ya que estos vectores no son linealmente independientes (digo son 4 vectores en un espacio de dimensión 3)

            Por lo tanto no es inyectiva.

            \textbf{\\Suprayectiva}

            Para que fuera supreyectiva, una base de $\mathbb{R}^2$ tras ser transformada debería ser un capaz de
            generar a $\mathbb{R}^3$ pero propongamos a la base canonica y ya vimos que esto no lo hace.

            Por lo tanto no es Suprayectiva :(


    % =====================================================
    % ============           ISOMORFISMO            =======
    % =====================================================
    \clearpage
    \section{Isomorfismo}
        Sea $\LinealTransformation : V \to W $ una transformación lineal.

        Decimos que $\LinealTransformation$ es un isoformismo y que V es isomorfo a W 
        ($V \cong W$) si $\LinealTransformation$ es biyectiva.

        Decir que $V$ sea isomorfo con $W$ quiere decir que existe alguna transformación
        lineal Biyectiva entre ambas.

        % ====================================
        % =========   PROPIEDADES    =========
        % ====================================
        \subsection{Propiedades}

            \textbf{\\Inverso}

            Algo interesante que recordar es que (obviamente) también
            $\LinealTransformation^-1 : W \to V $ es una transformación lineal
            y también es un isomorfismo.

            \textbf{\\Equivalencia}

            Podemos ademas saber que $\cong$ es una relación de equivalencia.
            Esto quiere decir que:

            \begin{itemize}
                \item $V \cong V$
                \item $(V \cong W)$, entonces $(W \cong V)$
                \item $(V \cong W)$ y $(W \cong U)$, entonces $(V \cong U)$
            \end{itemize}

            \textbf{\\Se Conservan Propiedades}

            Cualquier propiedad que tuviera un conjunto de vectores en $V$ se mantiene
            en su imagen, es decir se mantienen después de que le apliquemos la
            transformación lineal, si eran linealmente independientes, lo segirán siendo,
            si eran un subespacio, lo seguiran siendo y así.

            \textbf{\\Simplicidad de los Espacios Equivalentes}

            Supongamos que tenemos una transformación lineal entre dos espacios que ya
            sabemos que son isomorfos, entonces cualquiera de las siguientes 3 proposiciones
            son equivalentes, es decir, con que vamos que alguna es cierta, es obvio que las
            demas tambien lo son y con que una sea falsa, todas las demas son falsas.
            \emph{Nota muy importante en que solo aplica para espacios en los que sabemos que ya sabemos que son isomorfos.}

            \begin{tasks}(3)
                \task $\LinealTransformation$ es Inyectiva
                \task $\LinealTransformation$ es Suprayectiva
                \task $\LinealTransformation$ es Biyectiva
            \end{tasks}



        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Verificar si las siguiente transformación lineal si es un isomorfo:
            $\LinealTransformation : \mathbb{R}^3 \to \mathbb{R}_2[x]$ tal que: 
            \begin{equation*}
            \LinealTransformation(\begin{matrix}a\\b\\c\end{matrix}) = (a+b)+(a+c)x+(b+c)x^2
            \end{equation*}


            \textbf{\\Inyectiva}

            Podemos ver que el Kernel solo contiene el cero vector, todo lo que hay que hacer es
            que hay que ver el que cualquier elemento del Kernel tiene que ser aquel con $a=b=c=0$
            para verlo basta ve la matriz:

            \begin{equation*}
            \begin{pmatrix}1&1&0\\1&0&1\\0&1&1\end{pmatrix}
                \begin{pmatrix}a\\b\\c\end{pmatrix}=
                \begin{pmatrix}0\\0\\0\end{pmatrix}
            \end{equation*}

            Y vemos que su determiante no es cero (es 2 :p) por lo tanto el sistema homogeneo solo
            tiene la solución trivial, es decir, donde todo es cero.

            Por lo tanto es Inyectiva.

            \textbf{\\Suprayectiva}

            Lo que nos piden es ver que:
            \begin{equation*}
                \LinealTransformation(\begin{matrix}a\\b\\c\end{matrix}) = (a_0) +(a_1)x+(a_2)x^2
            \end{equation*}

            Es decir:

            \begin{equation*}
                \begin{pmatrix}1&1&0\\1&0&1\\0&1&1\end{pmatrix}
                \begin{pmatrix}a\\b\\c\end{pmatrix}
                =
                \begin{pmatrix}a_0\\a_1\\a_2\end{pmatrix}
            \end{equation*}

            Y vemos que esto si que genera a $\mathbb{R}_2[x]$

            Por lo tanto es Inyectiva.  

            Por lo tanto si que es Isomorfica.   


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Verificar si las siguiente transformación lineal si es un isomorfo:
            $\LinealTransformation : \mathbb{R}^3 \to \mathbb{R}_2[x]$ tal que: 
            \begin{equation*}
                \LinealTransformation(\begin{matrix}a\\b\\c\end{matrix}) = (a+b-2c)+(a-2b+c)x+(-2a+b+c)x^2
            \end{equation*}

            \textbf{\\Inyectiva}

            Podemos intentar ver que el Kernel solo contiene el cero vector, todo lo que hay que hacer es
            que hay que ver el que cualquier elemento del Kernel tiene que ser aquel con $a=b=c=0$
            para verlo basta ve la matriz:

            $\begin{pmatrix}1&1&-2\\1&-2&1\\-2&1&1\end{pmatrix} \begin{pmatrix}a\\b\\c\end{pmatrix}=
                \begin{pmatrix}0\\0\\0\end{pmatrix}$

            Y vemos que su determiante es cero por lo tanto el sistema homogeneo NO solo
            tiene la solución trivial, es decir, donde todo es cero.

            Por lo tanto es NO Inyectiva.

            Por lo tanto NO es Isomorfica.


    % ====================================
    % =========   PROPIEDADES    =========
    % ====================================
    \clearpage
    \section{Gran Teorema de Algebra Lineal}

        Dada una Matriz ($M_{n \times n} (K)$) y sea una Transformación Lineal
        ($\LinealTransformation : K^n \to K^n$) dada por: $T(x) = Ax$, es decir
        la transformación es solo multiplicar a cualquier vector por la Matriz ya 
        dicha.

        Entonces todas las siguientes proposiciones son equivalentes:
        \begin{itemize}
            \item $A$ es invertible
            \item $det(A)$ es diferente de cero
            \item El sistema homogeneo $A$ solo tiene una unica solución 
            \item $\LinealTransformation$ es Inyectiva, y todo a lo que es equivalente:
                \begin{itemize}
                    \item Su Kernel solo tiene al cero vector
                    \item La dimensión del Kernel es cero
                \end{itemize}

            \item $\LinealTransformation$ es Suprayectiva, y todo a lo que es equivalente.
                \begin{itemize}
                    \item Su Imagen tiene a todo $K^n$
                    \item La dimensión de la Imagen es $n$
                \end{itemize}
            \item $\LinealTransformation$ es Biyectiva
        \end{itemize}

% ======================================================================================
% ==========================       MATRIZ ASOCIADA                 =====================
% ======================================================================================
\chapter{Matriz Asociada}

    % =====================================================
    % ============           MATRIZ ASOCIADA        =======
    % =====================================================
    \clearpage
    \section{Matriz Asociada a Sistemas de C.}
        Sea $\LinealTransformation : V \to W $ una transformación lineal.
        
        Decimos que la matriz asociada a la $\LinealTransformation$ respecto a las Bases 
        $B_{1}(V)$ y a $B_{2}(W)$

        Donde:
        \begin{equation*}
            [\LinealTransformation]_{B_{1}(V) \to B_{2}(W)} = 
            \left(
                [\LinealTransformation(v_1)]_{B_{2}(W)}
                [\LinealTransformation(v_2)]_{B_{2}(W)}
                \cdots
                [\LinealTransformation(v_n)]_{B_{2}(W)}
            \right)
        \end{equation*}


        % ====================================
        % =========   PROPIEDADES    =========
        % ====================================
        \clearpage
        \section{Propiedades}

            Veamos que necesitamos primero para empezar:
            
            \begin{itemize}
                \item Sea las Transformaciones Lineales 
                    \begin{equation*}
                        \LinealTransformation_1,
                        \LinealTransformation_2,
                        \LinealTransformation_3 : W \to V
                    \end{equation*}

                \item Sea la Transformación Lineal $\LinealTransformation_4: V \to U$
                
                \item Sean $B_1, B_2, B_3$ bases de V
                
                \item Sean $B_4, B_5, B_6$ bases de W
                
                \item Sean $B_7$ bases de U
            \end{itemize}

            Ahora si, con todo listo veamos:
            \begin{itemize}
                \item \begin{equation*}
                        [\LinealTransformation_1 + \LinealTransformation_2]_{B_1 \to B_4} = 
                            [\LinealTransformation_1]_{B_1 \to B_4}
                            +
                            [\LinealTransformation_2]_{B_1 \to B_4}
                    \end{equation*}
                
                \item \begin{equation*}
                        [\alpha \LinealTransformation_1]_{B_1 \to B_4} = 
                            \alpha [\LinealTransformation_1]_{B_1 \to B_4}
                    \end{equation*}

                \item \begin{equation*}
                        [\LinealTransformation_4 \circ \LinealTransformation_1]_{B_7 \to B_1} = 
                            [\LinealTransformation_4]_{B_7 \to B_1}
                            [\LinealTransformation_1]_{B_1 \to B_7}
                    \end{equation*}

                \item\begin{equation*}
                        [\LinealTransformation_1]_{B_2 \to B_5} = 
                            C_{\frac{B_5}{B_4}}
                            [\LinealTransformation_1]_{B_1 \to B_4}
                            C_{\frac{B_1}{B_2}}
                    \end{equation*}

            \end{itemize}


        Esto es muy abstracto, así que lo mejor es mostrar un ejemplo:


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}

            Tengamos una $\LinealTransformation : \Real \to \Real^2$  que la podemos ver como:
            $\begin{pmatrix} 2x&-y&z\\-x&y&3z\end{pmatrix}$

            Tengamos dos Bases, digamos:
            \begin{itemize}
                \item $B_1$ La Base canónica:
                    \begin{equation*}
                        \begin{pmatrix} 1\\0\\0\end{pmatrix}, 
                        \begin{pmatrix} 0\\1\\0\end{pmatrix}, 
                        \begin{pmatrix} 0\\0\\1\end{pmatrix}
                    \end{equation*}

                \item $B_2$ La Base canónica:
                    \begin{equation*}
                        \begin{pmatrix} 1\\0\end{pmatrix}, 
                        \begin{pmatrix} 0\\1\end{pmatrix}, 
                    \end{equation*}
            \end{itemize}



            Entonces tenemos que:
            \begin{equation*}
            \begin{split}
                [\LinealTransformation]_{B_{1}(\Real^3) \to B_{2}(\Real^2)} &= 
                \left(
                    \left[\LinealTransformation(\begin{pmatrix} 1\\0\\0\end{pmatrix}\right]_{B_{2}(\Real^2))}
                    \left[\LinealTransformation(\begin{pmatrix} 0\\1\\0\end{pmatrix}\right]_{B_{2}(\Real^2))}
                    \left[\LinealTransformation(\begin{pmatrix} 0\\0\\1\end{pmatrix}\right]_{B_{2}(\Real^2))}
                \right)\\
                &=
                \left(
                    \begin{pmatrix} 2 \\-1\end{pmatrix}_{B_{2}(\Real^2)}
                    \begin{pmatrix} -1\\ 1\end{pmatrix}_{B_{2}(\Real^2)}
                    \begin{pmatrix} 1 \\ 3\end{pmatrix}_{B_{2}(\Real^2)}
                \right)\\
                &=
                \begin{pmatrix} 2&-1&1\\-1&1&3\end{pmatrix}
            \end{split}
            \end{equation*}



        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}

            Tengamos una $\LinealTransformation : \Real^2 \to \Real^2$  que la podemos ver como:
            $\LinealTransformation\begin{pmatrix}x\\y\end{pmatrix} = \begin{pmatrix} x+2y\\-y\end{pmatrix}$

            Tengamos dos Bases, digamos:
            \begin{itemize}
                \item $B_1$ Una base fea como:
                    \begin{equation*}
                        \begin{pmatrix} 1\\0\end{pmatrix}, 
                        \begin{pmatrix} 1\\1\end{pmatrix}, 
                    \end{equation*}

                \item $B_2$ Otra base fea:
                    \begin{equation*}
                        \begin{pmatrix} 1\\1 \end{pmatrix}, 
                        \begin{pmatrix} -1\\1\end{pmatrix}, 
                    \end{equation*}

                \item $B_3$ Ahora si la canónica:
                    \begin{equation*}
                        \begin{pmatrix} 1\\0 \end{pmatrix}, 
                        \begin{pmatrix} 0\\1 \end{pmatrix}, 
                    \end{equation*}
            \end{itemize}

            Entonces tenemos que si quisieramos encontrar $[\LinealTransformation]$
            solo habría que factorizar las incognitas:


            \begin{equation*}
            \begin{split}
                [\LinealTransformation]_{B_{3}(\Real^2) \to B_{3}(\Real^2)} &= 
                \left(
                    \left[\LinealTransformation(\begin{pmatrix} 1\\0\end{pmatrix}\right]_{B_{3}(\Real^2))}
                    \left[\LinealTransformation(\begin{pmatrix} 0\\1\end{pmatrix}\right]_{B_{3}(\Real^2))}
                \right)\\
                &=
                \left(
                    \begin{pmatrix} 1\\0 \end{pmatrix}_{B_{2}(\Real^2)}
                    \begin{pmatrix} 0\\-1\end{pmatrix}_{B_{2}(\Real^2)}
                \right)\\
                &=
                \begin{bmatrix} 1 & 0 \\ 0 & -1\end{bmatrix}
            \end{split}
            \end{equation*}

    % =====================================================
    % ============           MATRIZ SEMEJANTE       =======
    % =====================================================
    \clearpage
    \section{Matriz Semejante}
        Sea $A, B$ y $P \in M_{n \times n} (K)$.

        Decimos que A es semejante a B si existe una $P$ invertible tal que se cumpla que:

        \begin{equation}
            B = P^{-1}AP
        \end{equation}

        Es más, esta semejanza es una relación de equivalencia.


        Podemos descubrir que A es semejante a B si y solo si A y B son matrices asociadas a
        transformaciones lineales del estilo $\LinealTransformation : K^n \to K^n$ con la misma
        base en el dominio que el contradominio.





% ======================================================================================
% ==========================     DIAGONALIZACION                   =====================
% ======================================================================================
\chapter{Valores y Vectores Propios}

    % =====================================================
    % ============           MATRIZ ASOCIADA        =======
    % =====================================================
    \clearpage
    \section{Valor Característico}

        Veamos que pasa si $K = \Complex$ y sea $A \in M_{n \times n} (K)$.
        Decimos que $v \in K^n$ con $v \neq 0_{n \times 1}$ es un vector propio
        de A si existe un $\alpha \in K$ tal que :

        \begin{equation}
            Av = \alpha v
        \end{equation}

        Además decimos que $\alpha$ es un valor propio de A.


        Sea $A \in M_{n \times n} (K)$ y sea $\beta$ un valor caracteristico que ya conocemos
        entonces podemos definir al subespacio asociado a $\beta$, como:

        \begin{equation}
            E_{\beta} = \{v \in K^n | Av = \beta v \}
        \end{equation}

        Tambien podemos ver que para encontrar los valores caracteristicos, gracias a la definición basta
        con que saquemos el determinante de esta expresión:
        \begin{equation}
            |A - \beta I_n|
        \end{equation}

        Y veamos para cuales valores de $\beta$ el determinante da 0.



        % ====================================
        % =========   PROPIEDADES    =========
        % ====================================
        \clearpage
        \subsection{Propiedades}

        Sea $A \in M_{n \times n} (K)$ y sea $\beta ,\beta_1, \beta_2$ un valores característicos de A.

        Sea $v_1$ y $v_2$ vectores característicos asociados a $\beta_1$ y $\beta_2$ respectivamente.

        Entonces tenemos que:

        \begin{itemize}  
            \item $E_{\beta}$ es un subespacio vectorial de $k^n$
            \item Si $\beta_1 \neq \beta_2$, entonces $E_{\beta_1} 1 \cup E_{\beta_2} = \{0_v\}$
            \item Si $\beta_1 \neq \beta_2$, entonces $v_1$ y $v_2$ son linealmente independientes.
        \end{itemize}  


        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Encuentra si $v$ es un vector propio de A, dados:

            $A = \begin{pmatrix}4&4&2\\0&2&1\\3&2&1\end{pmatrix}$ y sea 
            $v = \begin{pmatrix}1\\\frac{1}{6}\\\frac{2}{3}\end{pmatrix}$

            Y vemos que lo es, pues:

            \begin{equation*}
            \begin{split}
                \begin{pmatrix}4&4&2\\0&2&1\\3&2&1\end{pmatrix}
                \begin{pmatrix}1\\\frac{1}{6}\\\frac{2}{3}\end{pmatrix} =
                \begin{pmatrix}6\\1\\4\end{pmatrix} =
                6\begin{pmatrix}1\\\frac{1}{6}\\\frac{2}{3}\end{pmatrix}
            \end{split}
            \end{equation*}
        

        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Encuentra el espacio generador por el valor característico 
            $\beta = -2$ donde:

            $A = \begin{pmatrix}10&-18\\6&-11\end{pmatrix}$.

            Así que empecemos:

            \begin{equation*}
            \begin{split}
                E_{\beta} &= \{v \in K^n | Av = \beta v \}  \\
                E_{-2} &= \{v \in K^2 | Av = (-2) v \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 | Av = (-2) v \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 | Av = (-2) v \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 |
                \begin{pmatrix}10&-18\\6&-11\end{pmatrix}v = (-2) v \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 |
                \begin{pmatrix}10&-18\\6&-11\end{pmatrix}  \begin{pmatrix}x_1\\x_2\end{pmatrix} 
                = (-2) \begin{pmatrix}x_1\\x_2\end{pmatrix} \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 |
                \begin{pmatrix}10x_1&-18x_2x_1\\6x_1&-11x_2\end{pmatrix}  - \begin{pmatrix}2x_1\\2x_2\end{pmatrix} 
                = \begin{pmatrix}0\\0\end{pmatrix} \} \\
                E_{-2} &= \{ \begin{pmatrix}x_1\\x_2\end{pmatrix} \in K^2 |
                \begin{pmatrix}12x_1&-18x_2\\6x_1&-0x_2\end{pmatrix}
                = \begin{pmatrix}0\\0\end{pmatrix} \}
            \end{split}
            \end{equation*}


            Ahora aplicas Gauss-Jordan, donde partimos de a :
            $$\begin{pmatrix}12 & -18 \\6 & -9\end{pmatrix}$$

            Donde ahora tenemos que llegamos a:
            $$\begin{pmatrix}1 & -\frac{3}{2} \\ 0 & 0\end{pmatrix}$$

            Por lo tanto son cualquier vector que cumpla que:
            $x_1 -\frac{3}{2}x_2 = 0$, es decir que $x_1 = \frac{3}{2}$
            
            Por lo tanto podemos reescribir nuestro vector como:
            $\begin{pmatrix} \frac{3}{2}x_2 \\ x_2\end{pmatrix}$

            Que si te das cuenta los los vectores que se generan con esta base:
            $ \{ x_2 <\begin{pmatrix}\frac{3}{2} \\ 1\end{pmatrix}> \}$
            

        % ========================
        % =====   EJEMPLO    =====
        % ========================
            \clearpage
            \subsubsection{Ejemplo}
            Encuentra los vectores caracteristicos de A, donde:

            $A = \begin{pmatrix}10&-18\\6&-11\end{pmatrix}$.

            Así que empecemos:

            \begin{equation*}
            \begin{split}
                \left|A - \beta I_n \right| &= 0 \\
                \left|\begin{pmatrix}10&-18\\6&-11\end{pmatrix} - \beta \begin{pmatrix}1&0\\0&1\end{pmatrix}\right| &= 0 \\
                \left|\begin{pmatrix}10 -\beta&-18\\6&-11-\beta\end{pmatrix} \right| &= 0 \\
                (10-\beta)(-11 -\beta) -6(-18)  &= 0 \\
                \beta^2 + \beta -2 &= 0 \\
            \end{split}
            \end{equation*}

            Por lo tanto encontramos que $\beta_1 = -2 $ y $ \beta_2 = 1$


        
        


% =====================================================
% ============        BIBLIOGRAPHY   ==================
% =====================================================
\clearpage
\bibliographystyle{plain}
    \begin{thebibliography}{9}

    % ============ REFERENCE #1 ========
    \bibitem{Sitio1} 
        ProbRob
        \\\texttt{Youtube.com}


     

\end{thebibliography}



\end{document}